{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#TEST_PATH = 'input/modicyeni/test/images'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH='E://mehmetyuksek//ircad-dataset//input/malign\\\\'\n",
    "TEST_PATH='E:\\\\mehmetyuksek\\\\ircad-dataset\\\\input\\\\mtest\\\\'\n",
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deneme_Path_Train=\"E:\\\\saglikyenicalisma\\\\segmentation_models-master1\\\\segmentation_models-master\\\\examples\\\\deneme65\\\\malign\\\\\"\n",
    "Deneme_Path_Test=\"E:\\\\saglikyenicalisma\\\\segmentation_models-master1\\\\segmentation_models-master\\\\examples\\\\deneme65\\\\bening\\\\\"\n",
    "train_ids = next(os.walk(Deneme_Path_Train))[2]\n",
    "test_ids = next(os.walk(Deneme_Path_Test))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bilal hocanın dataseti için bunu kullanıyoruz\n",
    "\n",
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = Deneme_Path_Train + id_\n",
    "    img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    #print(img.shape)\n",
    "    X_train[n] = img\n",
    "    \n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path1 = Deneme_Path_Test+id_\n",
    "    img = imread(path1)[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img    \n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_malign_5\",X_train)\n",
    "np.save(\"X_bening_5\",X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bilal hocanın dataseti için bunu kullanıyoruz\n",
    "\n",
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_[2:] + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    #print(img.shape)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        #print(mask.shape)\n",
    "        #print(mask_.shape)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "        #print(mask)\n",
    "    Y_train[n] = mask\n",
    "    #print(Y_train[n])\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_[2:] + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_test[n] = mask\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TEST_PATH='E:\\\\mehmetyuksek\\\\ircad-dataset\\\\input\\\\bmtest\\\\'\n",
    "# Get train and test IDs\n",
    "\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_[2:] + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_test[n] = mask\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"x_train_b.npy\",X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"y_train_b.npy\",Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"x_test_b.npy\",X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"y_test_b.npy\",Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load(\"beningmaligndataset/x_train_bm.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=np.load(\"beningmaligndataset/y_train_bm.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.load(\"beningmaligndataset/x_test_bm.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=np.load(\"beningmaligndataset/y_test_bm.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Y_train=Y_train.astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Y_test=Y_test.astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'inceptionv3'\n",
    "#efficientnetb0 seresnet101\n",
    "BATCH_SIZE = 8\n",
    "CLASSES = ['malignant']\n",
    "LR = 0.0001\n",
    "EPOCHS = 100\n",
    "threshold1=0.5\n",
    "\n",
    "#preprocess_input = sm.get_preprocessing(BACKBONE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network parameters\n",
    "n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES) + 1)  # case for binary and multiclass segmentation\n",
    "activation = 'sigmoid' if n_classes == 1 else 'softmax'\n",
    "\n",
    "#create model\n",
    "model = sm.FPN(BACKBONE, classes=n_classes, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optomizer\n",
    "import keras\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "    \n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=threshold1), sm.metrics.FScore(threshold=threshold1),sm.metrics.Precision(threshold=threshold1),sm.metrics.Recall(threshold=threshold1)]\n",
    "\n",
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model.compile(optim, total_loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "\n",
    "\"\"\"callbacks = [\n",
    "    #EarlyStopping(patience=50, verbose=1),\n",
    "    #ReduceLROnPlateau(monitor='val_acc',factor=0.01, patience=15, min_lr=0.0001, verbose=1),\n",
    "    ModelCheckpoint('hematadam05042021rmsprop.h5', verbose=1, save_best_only=True)]\"\"\"\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('./best_model_b_thres'+str(threshold1)+'_'+BACKBONE+'.h5', save_best_only=True, mode='max',verbose=1, monitor='val_iou_score')    \n",
    "]\n",
    "#callbacks = [EarlyStopping(patience=250, verbose=1),\n",
    "#ModelCheckpoint('modelmalign08092020-a.h5', verbose=1, save_best_only=True)]\n",
    "results = model.fit(X_train, Y_train, validation_split=0.20, batch_size=8, epochs=500,callbacks=callbacks,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation iou_score values\n",
    "plt.figure(figsize=(15, 5),dpi=300)\n",
    "plt.subplot(121)\n",
    "plt.plot(results.history['iou_score'])\n",
    "plt.plot(results.history['val_iou_score'])\n",
    "plt.title('Model iou_score')\n",
    "plt.ylabel('iou_score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(122)\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.models_factory import ModelsFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelsFactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE=\"deneme\"\n",
    "def evaluateModel1(model, X_test, Y_test, batchSize):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs('results'+BACKBONE)\n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "\n",
    "    yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
    "\n",
    "    yp = np.round(yp,0)\n",
    "\n",
    "    for i in range(len(Y_test)):\n",
    "\n",
    "     \n",
    "        image1_mask = np.array(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
    "        image1_mask = np.ma.masked_where(image1_mask == 0, image1_mask)\n",
    "        fig, ax = plt.subplots(1,4,figsize = (20,10))\n",
    "        ax[0].imshow(X_test[i], cmap = 'gray')\n",
    "        ax[0].set_title('Input')\n",
    "        \n",
    "        ax[1].imshow(Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1]), cmap = 'gray')\n",
    "        ax[1].set_title('Ground Truth')\n",
    "        ax[2].imshow(image1_mask, cmap = 'gray')\n",
    "        ax[2].set_title('Prediction')\n",
    "\n",
    "        ax[3].imshow(X_test[i], cmap = 'gray', interpolation = 'none')\n",
    "        ax[3].imshow(image1_mask, cmap = 'jet', interpolation = 'none', alpha = 0.7)\n",
    "        ax[3].set_title('Last Segmentation')\n",
    "\n",
    "        intersection = yp[i].ravel() * Y_test[i].ravel()\n",
    "        union = yp[i].ravel() + Y_test[i].ravel() - intersection\n",
    "\n",
    "        jacard = (np.sum(intersection)/np.sum(union))  \n",
    "        fig.suptitle('Jacard Index:'+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +'='+str(jacard))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        fig.savefig('results'+BACKBONE+'/'+str(i)+'.png',format='png')\n",
    "        \n",
    "\n",
    "\n",
    "    jacard = 0\n",
    "    dice = 0\n",
    "    \n",
    "    \n",
    "    for i in range(len(Y_test)):\n",
    "        yp_2 = yp[i].ravel()\n",
    "        y2 = Y_test[i].ravel()\n",
    "        \n",
    "        intersection = yp_2 * y2\n",
    "        union = yp_2 + y2 - intersection\n",
    "\n",
    "        jacard += (np.sum(intersection)/np.sum(union))  \n",
    "\n",
    "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
    "\n",
    "    \n",
    "    jacard /= len(Y_test)\n",
    "    dice /= len(Y_test)\n",
    "    \n",
    "\n",
    "\n",
    "    print('Jacard Index : '+str(jacard))\n",
    "    print('Dice Coefficient : '+str(dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE=\"deneme\"\n",
    "def evaluateModel2(model, X_test,  batchSize):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs('results'+BACKBONE)\n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "\n",
    "    yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
    "\n",
    "    yp = np.round(yp,0)\n",
    "\n",
    "    for i in range(5):\n",
    "\n",
    "     \n",
    "        image1_mask = np.array(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
    "        image1_mask = np.ma.masked_where(image1_mask == 0, image1_mask)\n",
    "        fig, ax = plt.subplots(1,3,figsize = (20,10))\n",
    "        ax[0].imshow(X_test[i], cmap = 'gray')\n",
    "        ax[0].set_title('Input')\n",
    "        \n",
    "        \n",
    "        ax[1].imshow(image1_mask, cmap = 'gray')\n",
    "        ax[1].set_title('Prediction')\n",
    "\n",
    "        ax[2].imshow(X_test[i], cmap = 'gray', interpolation = 'none')\n",
    "        ax[2].imshow(image1_mask, cmap = 'jet', interpolation = 'none', alpha = 0.7)\n",
    "        ax[2].set_title('Last Segmentation')\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        fig.savefig('results'+BACKBONE+'/'+str(i)+'.png',format='png')\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = load_model(\"E:/saglikyenicalisma/segmentation_models-master1/segmentation_models-master/examples/bilahocasonuclarsegmentation/bmsonuc/linknet/linknetbmseresnet/best_model_b_thres0.5_seresnet101.h5\",compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load(\"X_malign_5.npy\")\n",
    "X_test=np.load(\"X_bening_5.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateModel2(res, X_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateModel1(model, X_train, Y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateModel1(model, X_train[50:100], Y_train[50:100], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"best_model_Effnetb0.h5\",custom_objects={'dice_loss_plus_1binary_focal_loss': total_loss,'iou_score':sm.metrics.IOUScore(threshold=0.5),'f1-score':sm.metrics.FScore(threshold=0.5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy=load_model(\"best_model_Effnetb0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model_resnet34.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File('best_model_Effnetb0.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = f['model_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cset=dset['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cset.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
